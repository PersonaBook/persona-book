"""
ì±•í„° ë²ˆí˜¸ë¥¼ êµ¬ì²´ì ì¸ ë‚´ìš©ìœ¼ë¡œ ë§¤í•‘í•˜ëŠ” ìœ í‹¸ë¦¬í‹°
- JSON ê¸°ë°˜ í‚¤ì›Œë“œ ì‹œìŠ¤í…œ
- í˜ì´ì§€ ë²”ìœ„ ì§€ì›
- í–¥ìƒëœ ë§¤í•‘ ì•Œê³ ë¦¬ì¦˜
"""
import json
import re
import os
from typing import Dict, List, Optional, Tuple
from pathlib import Path

# ì „ì—­ í‚¤ì›Œë“œ ë°ì´í„° ìºì‹œ
_keywords_cache = None

def load_keywords_data() -> Dict:
    """í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ JSON íŒŒì¼ì—ì„œ ë¡œë“œ"""
    global _keywords_cache
    if _keywords_cache is not None:
        return _keywords_cache
    
    keywords_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'keywords.json')
    try:
        with open(keywords_path, 'r', encoding='utf-8') as f:
            _keywords_cache = json.load(f)
            print(f"âœ… í‚¤ì›Œë“œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(_keywords_cache['chapters'])}ê°œ ì±•í„°")
            return _keywords_cache
    except FileNotFoundError:
        print(f"âŒ í‚¤ì›Œë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {keywords_path}")
        return {"chapters": {}}
    except json.JSONDecodeError as e:
        print(f"âŒ í‚¤ì›Œë“œ íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return {"chapters": {}}

def extract_chapter_info(user_input: str) -> Tuple[Optional[str], List[str]]:
    """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì±•í„° ë²ˆí˜¸ì™€ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    input_normalized = user_input.strip().lower()
    
    # ì±•í„° ë²ˆí˜¸ ì¶”ì¶œ
    chapter_patterns = [
        r'ì±•í„°\s*(\d+)',
        r'chapter\s*(\d+)',
        r'(\d+)ì¥',
        r'(\d+)ì±•í„°',
        r'^(\d+)$'
    ]
    
    chapter_num = None
    for pattern in chapter_patterns:
        match = re.search(pattern, input_normalized)
        if match:
            chapter_num = match.group(1)
            break
    
    # ì¶”ê°€ í‚¤ì›Œë“œ ì¶”ì¶œ (ì±•í„° ë²ˆí˜¸ ì œì™¸)
    additional_keywords = []
    if chapter_num:
        # ì±•í„° ë²ˆí˜¸ ê´€ë ¨ í…ìŠ¤íŠ¸ ì œê±° í›„ ë‚˜ë¨¸ì§€ í‚¤ì›Œë“œ ì¶”ì¶œ
        clean_input = re.sub(r'(ì±•í„°|chapter|ì¥)\s*\d+|\d+\s*(ì±•í„°|chapter|ì¥)', '', input_normalized)
        additional_keywords = [word.strip() for word in clean_input.split() if word.strip()]
    else:
        # ì±•í„° ë²ˆí˜¸ê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í‚¤ì›Œë“œë¡œ ì²˜ë¦¬
        additional_keywords = [word.strip() for word in input_normalized.split() if word.strip()]
    
    return chapter_num, additional_keywords

def find_best_chapter_match(keywords: List[str]) -> Optional[str]:
    """í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ì±•í„° ì°¾ê¸°"""
    keywords_data = load_keywords_data()
    chapters = keywords_data.get('chapters', {})
    
    if not keywords:
        return None
    
    chapter_scores = {}
    
    for chapter_id, chapter_info in chapters.items():
        score = 0
        chapter_keywords = [kw.lower() for kw in chapter_info.get('keywords', [])]
        
        for user_keyword in keywords:
            # ì •í™•í•œ ë§¤ì¹˜
            if user_keyword in chapter_keywords:
                score += 3
            # ë¶€ë¶„ ë§¤ì¹˜
            elif any(user_keyword in ck or ck in user_keyword for ck in chapter_keywords):
                score += 1
        
        if score > 0:
            chapter_scores[chapter_id] = score
    
    if chapter_scores:
        best_chapter = max(chapter_scores, key=chapter_scores.get)
        print(f"ğŸ¯ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì±•í„° {best_chapter} ì„ íƒë¨ (ì ìˆ˜: {chapter_scores[best_chapter]})")
        return best_chapter
    
    return None

def get_chapter_content(chapter_id: str) -> str:
    """ì±•í„° IDë¡œë¶€í„° ê²€ìƒ‰ìš© ì»¨í…ì¸  ìƒì„±"""
    keywords_data = load_keywords_data()
    chapters = keywords_data.get('chapters', {})
    
    if chapter_id not in chapters:
        return ""
    
    chapter_info = chapters[chapter_id]
    title = chapter_info.get('title', '')
    keywords = chapter_info.get('keywords', [])
    
    # ì œëª©ê³¼ í‚¤ì›Œë“œë¥¼ ê²°í•©í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    content = f"{title} {' '.join(keywords)}"
    return content

def map_chapter_to_content(user_input: str) -> str:
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ êµ¬ì²´ì ì¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ë³€í™˜
    
    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥ (ì˜ˆ: "3", "ì±•í„° 3", "4ì¥", "ë°°ì—´" ë“±)
        
    Returns:
        êµ¬ì²´ì ì¸ ê²€ìƒ‰ ì¿¼ë¦¬ ë¬¸ìì—´
    """
    if not user_input or user_input.strip() == "":
        return "Java í”„ë¡œê·¸ë˜ë°"
    
    # ì±•í„° ì •ë³´ì™€ í‚¤ì›Œë“œ ì¶”ì¶œ
    chapter_num, additional_keywords = extract_chapter_info(user_input)
    
    print(f"ğŸ” ì…ë ¥ ë¶„ì„: ì±•í„°={chapter_num}, í‚¤ì›Œë“œ={additional_keywords}")
    
    target_chapter = None
    
    # 1. ëª…ì‹œì  ì±•í„° ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°
    if chapter_num:
        keywords_data = load_keywords_data()
        if chapter_num in keywords_data.get('chapters', {}):
            target_chapter = chapter_num
            print(f"âœ… ëª…ì‹œì  ì±•í„° {chapter_num} ë§¤í•‘ë¨")
    
    # 2. í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­
    if not target_chapter and additional_keywords:
        target_chapter = find_best_chapter_match(additional_keywords)
    
    # 3. ì „ì²´ ì…ë ¥ì„ í‚¤ì›Œë“œë¡œ ë§¤ì¹­ ì‹œë„
    if not target_chapter:
        all_keywords = [word.strip() for word in user_input.lower().split() if word.strip()]
        target_chapter = find_best_chapter_match(all_keywords)
    
    # ê²°ê³¼ ìƒì„±
    if target_chapter:
        content = get_chapter_content(target_chapter)
        # ì¶”ê°€ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í¬í•¨
        if additional_keywords:
            content += " " + " ".join(additional_keywords)
        print(f"ğŸ¯ ìµœì¢… ë§¤í•‘: ì±•í„° {target_chapter} -> {content[:100]}...")
        return content
    else:
        # ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
        print(f"âš ï¸ ë§¤í•‘ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {user_input}")
        return user_input

def get_chapter_page_range(chapter_id: str) -> Optional[Tuple[int, int]]:
    """ì±•í„°ì˜ í˜ì´ì§€ ë²”ìœ„ ë°˜í™˜"""
    keywords_data = load_keywords_data()
    chapters = keywords_data.get('chapters', {})
    
    if chapter_id in chapters:
        page_range = chapters[chapter_id].get('page_range')
        if page_range and len(page_range) == 2:
            return tuple(page_range)
    
    return None

def get_all_chapters_info() -> Dict:
    """ëª¨ë“  ì±•í„° ì •ë³´ ë°˜í™˜"""
    return load_keywords_data().get('chapters', {})

def get_chapter_definitions():
    """ì±•í„° ì •ì˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return {
        "2": {"name": "ë³€ìˆ˜", "start": 30, "end": 107},
        "3": {"name": "ì—°ì‚°ì", "start": 108, "end": 157},
        "4": {"name": "ì¡°ê±´ë¬¸ê³¼ ë°˜ë³µë¬¸", "start": 158, "end": 205},
        "5": {"name": "ë°°ì—´", "start": 206, "end": 253},
        "6": {"name": "ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° I", "start": 254, "end": 339}
    }

def load_keywords_for_chapter(chapter_num):
    """íŠ¹ì • ì±•í„°ì˜ í‚¤ì›Œë“œë“¤ì„ keywords_detailed.jsonì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        keywords_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'keywords_detailed.json')
        if not Path(keywords_path).exists():
            print(f"âš ï¸ í‚¤ì›Œë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {keywords_path}")
            return []
        
        with open(keywords_path, 'r', encoding='utf-8') as f:
            all_keywords = json.load(f)
        
        # ì±•í„° ì •ì˜ ê°€ì ¸ì˜¤ê¸°
        chapters = get_chapter_definitions()
        if chapter_num not in chapters:
            print(f"âš ï¸ ì±•í„° {chapter_num}ëŠ” ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        chapter_info = chapters[chapter_num]
        start_page = chapter_info['start']
        end_page = chapter_info['end']
        
        # í•´ë‹¹ ì±•í„° í˜ì´ì§€ ë²”ìœ„ì— ì†í•˜ëŠ” í‚¤ì›Œë“œë“¤ í•„í„°ë§
        chapter_keywords = []
        for keyword_data in all_keywords:
            keyword = keyword_data['word']
            pages = keyword_data['pages']
            
            # í‚¤ì›Œë“œì˜ í˜ì´ì§€ ì¤‘ í•˜ë‚˜ë¼ë„ ì±•í„° ë²”ìœ„ì— ì†í•˜ë©´ í¬í•¨
            for page in pages:
                if start_page <= page <= end_page:
                    chapter_keywords.append(keyword)
                    break
        
        print(f"ğŸ“š ì±•í„° {chapter_num} ({chapter_info['name']}) í‚¤ì›Œë“œ {len(chapter_keywords)}ê°œ ë¡œë“œë¨")
        return chapter_keywords
        
    except Exception as e:
        print(f"âŒ í‚¤ì›Œë“œ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def get_enhanced_chapter_content(chapter_num: str) -> str:
    """í–¥ìƒëœ ì±•í„° ì»¨í…ì¸  ìƒì„± - ì •ë°€í•œ í‚¤ì›Œë“œ ê¸°ë°˜"""
    try:
        chapter_keywords = load_keywords_for_chapter(chapter_num)
        if not chapter_keywords:
            # fallback to basic content
            return get_chapter_content(chapter_num)
        
        # ì±•í„° ì •ì˜ì—ì„œ ì œëª© ê°€ì ¸ì˜¤ê¸°
        chapters = get_chapter_definitions()
        chapter_title = chapters.get(chapter_num, {}).get('name', f'ì±•í„° {chapter_num}')
        
        # í‚¤ì›Œë“œë“¤ì„ ê²°í•©í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        keywords_text = ' '.join(chapter_keywords)
        content = f"{chapter_title} {keywords_text}"
        
        print(f"ğŸ¯ í–¥ìƒëœ ì±•í„° {chapter_num} ì»¨í…ì¸  ìƒì„±: {len(chapter_keywords)}ê°œ í‚¤ì›Œë“œ ì‚¬ìš©")
        return content
        
    except Exception as e:
        print(f"âŒ í–¥ìƒëœ ì»¨í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}")
        return get_chapter_content(chapter_num)  # fallback


def enhance_query_for_search(query: str) -> str:
    """
    ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ í–¥ìƒì‹œí‚´
    
    Args:
        query: ê¸°ë³¸ ì¿¼ë¦¬
        
    Returns:
        í–¥ìƒëœ ê²€ìƒ‰ ì¿¼ë¦¬
    """
    # ë§¤í•‘ëœ ì¿¼ë¦¬ì— Java ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€
    enhanced_query = f"Java {query} í”„ë¡œê·¸ë˜ë° ì˜ˆì œ ë¬¸ì œ"
    print(f"ğŸ” í–¥ìƒëœ ì¿¼ë¦¬: {enhanced_query}")
    return enhanced_query