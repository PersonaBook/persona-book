"""
GENERATING_ADDITIONAL_QUESTION_WITH_RAG API
ë¡œì»¬ ì„ë² ë”©ì„ ì‚¬ìš©í•œ ì¶”ê°€ ë¬¸ì œ ìƒì„± API
"""
import time
import base64
import tempfile
import os
from fastapi import APIRouter, HTTPException
from app.schemas.request.rag_apis import GeneratingAdditionalQuestionRequest
from app.schemas.response.rag_apis import GeneratingAdditionalQuestionResponse
from app.services.local_pdf_service import get_local_pdf_service
from app.services.enhanced_local_question_generator import get_enhanced_local_question_generator_service

router = APIRouter(tags=["Additional Question Generation"])


@router.post("/generate-additional-question-with-rag", response_model=GeneratingAdditionalQuestionResponse)
async def generate_additional_question_with_rag(request: GeneratingAdditionalQuestionRequest):
    """
    ë¡œì»¬ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€ ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    **í”„ë¡œì„¸ìŠ¤:**
    1. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹
    2. ë¡œì»¬ ì„ë² ë”©ì„ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê²€ìƒ‰
    3. ì´ì „ ë¬¸ì œì™€ ë‹¤ë¥¸ ìœ í˜•ì˜ ë¬¸ì œ ìƒì„±
    4. ì±•í„°ë³„ ë§ì¶¤í˜• ë¬¸ì œ í…œí”Œë¦¿ í™œìš©
    
    **íŠ¹ì§•:**
    - OpenAI API í• ë‹¹ëŸ‰ì— ì˜ì¡´í•˜ì§€ ì•ŠìŒ
    - ì´ì „ ë¬¸ì œì™€ ë‹¤ë¥¸ ìœ í˜•ìœ¼ë¡œ ìƒì„±
    - ë™ì¼í•œ ê°œë…ì— ëŒ€í•œ ë‹¤ì–‘í•œ ê´€ì 
    - í•™ìŠµ íš¨ê³¼ ê·¹ëŒ€í™”
    """
    start_time = time.time()
    temp_file_path = None
    
    try:
        # 1. Base64 ë¬¸ìì—´ì„ PDF íŒŒì¼ë¡œ ë””ì½”ë”©í•˜ì—¬ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        try:
            pdf_data = base64.b64decode(request.pdf_base64)
            print(f"ğŸ“„ ë””ì½”ë”©ëœ PDF ë°ì´í„° í¬ê¸°: {len(pdf_data)} bytes")
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
                temp_file.write(pdf_data)
                temp_file_path = temp_file.name
                print(f"ğŸ“ ì„ì‹œ PDF íŒŒì¼ ìƒì„±: {temp_file_path}")
                
            # íŒŒì¼ì´ ì œëŒ€ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
            import os
            if os.path.exists(temp_file_path):
                file_size = os.path.getsize(temp_file_path)
                print(f"ğŸ“Š ì„ì‹œ íŒŒì¼ í¬ê¸°: {file_size} bytes")
            else:
                print("âŒ ì„ì‹œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
                return GeneratingAdditionalQuestionResponse(
                    success=False,
                    message="PDF íŒŒì¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                    userId=request.userId,
                    bookId=request.bookId,
                    additional_question="",
                    correct_answer="",
                    explanation="",
                    difficulty=request.difficulty.value,
                    question_type=request.previous_question_type.value,
                    chunks_used=0,
                    processing_time=time.time() - start_time
                )
        except Exception as e:
            print(f"âŒ Base64 ë””ì½”ë”© ì˜¤ë¥˜: {e}")
            return GeneratingAdditionalQuestionResponse(
                success=False,
                message=f"PDF ë””ì½”ë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}",
                userId=request.userId,
                bookId=request.bookId,
                additional_question="",
                correct_answer="",
                explanation="",
                difficulty=request.difficulty.value,
                question_type=request.previous_question_type.value,
                chunks_used=0,
                processing_time=time.time() - start_time
            )

        # 2. PDF ì²˜ë¦¬ ë° ì²­í‚¹
        local_pdf_service = get_local_pdf_service()
        # max_pagesê°€ Noneì´ê±°ë‚˜ 5ë³´ë‹¤ ì‘ìœ¼ë©´ 20ìœ¼ë¡œ ì„¤ì •
        effective_max_pages = request.max_pages if request.max_pages and request.max_pages >= 5 else 20
        print(f"ğŸ“„ PDF ì²˜ë¦¬: ìµœëŒ€ {effective_max_pages}í˜ì´ì§€")
        
        chunks = local_pdf_service.process_pdf_and_create_chunks(
            temp_file_path,
            max_pages=effective_max_pages
        )

        if not chunks:
            return GeneratingAdditionalQuestionResponse(
                success=False,
                message="PDF ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                userId=request.userId,
                bookId=request.bookId,
                additional_question="",
                correct_answer="",
                explanation="",
                difficulty=request.difficulty.value,
                question_type=request.previous_question_type.value,
                chunks_used=0,
                processing_time=time.time() - start_time
            )

        # 3. í–¥ìƒëœ ë¡œì»¬ ë¬¸ì œ ìƒì„± ì„œë¹„ìŠ¤ ì„¤ì •
        enhanced_question_service = get_enhanced_local_question_generator_service()
        success = enhanced_question_service.setup_documents(chunks)
        if not success:
            return GeneratingAdditionalQuestionResponse(
                success=False,
                message="ë¬¸ì„œ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                userId=request.userId,
                bookId=request.bookId,
                additional_question="",
                correct_answer="",
                explanation="",
                difficulty=request.difficulty.value,
                question_type=request.previous_question_type.value,
                chunks_used=len(chunks),
                processing_time=time.time() - start_time
            )

        # 4. ì¶”ê°€ ë¬¸ì œ ìƒì„± (ì´ì „ê³¼ ë‹¤ë¥¸ ìœ í˜•)
        result = enhanced_question_service.generate_question_with_rag(
            request.query,
            request.difficulty.value,
            request.previous_question_type.value
        )
        
        if result["success"]:
            # ë¬¸ì œ í…ìŠ¤íŠ¸ ìƒì„±
            question_text = f"ë¬¸ì œ: {result['question']}\nì •ë‹µ: {result['answer']}\ní•´ì„¤: {result['explanation']}"
            
            processing_time = time.time() - start_time
            
            return GeneratingAdditionalQuestionResponse(
                success=True,
                message="ë¡œì»¬ ì„ë² ë”©ì„ ì‚¬ìš©í•œ ì¶”ê°€ ë¬¸ì œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                userId=request.userId,
                bookId=request.bookId,
                additional_question=result['question'],
                correct_answer=result['answer'],
                explanation=result['explanation'],
                difficulty=request.difficulty.value,
                question_type=request.previous_question_type.value,
                chunks_used=result.get('context_used', len(chunks)),
                processing_time=processing_time
            )
        else:
            return GeneratingAdditionalQuestionResponse(
                success=False,
                message=result["message"],
                userId=request.userId,
                bookId=request.bookId,
                additional_question="",
                correct_answer="",
                explanation="",
                difficulty=request.difficulty.value,
                question_type=request.previous_question_type.value,
                chunks_used=len(chunks),
                processing_time=time.time() - start_time
            )
        
    except Exception as e:
        processing_time = time.time() - start_time
        raise HTTPException(
            status_code=500, 
            detail=f"ì¶”ê°€ ë¬¸ì œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_file_path and os.path.exists(temp_file_path):
            os.remove(temp_file_path)


def _parse_generated_content(content: str) -> tuple[str, str, str]:
    """
    ìƒì„±ëœ ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ ë¬¸ì œ, ì •ë‹µ, í•´ì„¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        content: ìƒì„±ëœ ë‚´ìš©
        
    Returns:
        (ë¬¸ì œ, ì •ë‹µ, í•´ì„¤)
    """
    try:
        lines = content.split('\n')
        question = ""
        correct_answer = ""
        explanation = ""
        
        current_section = ""
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            if line.startswith("ë¬¸ì œ:"):
                current_section = "question"
                question = line.replace("ë¬¸ì œ:", "").strip()
            elif line.startswith("ì •ë‹µ:"):
                current_section = "answer"
                correct_answer = line.replace("ì •ë‹µ:", "").strip()
            elif line.startswith("í•´ì„¤:"):
                current_section = "explanation"
                explanation = line.replace("í•´ì„¤:", "").strip()
            else:
                if current_section == "question":
                    question += " " + line
                elif current_section == "answer":
                    correct_answer += " " + line
                elif current_section == "explanation":
                    explanation += " " + line
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if not question:
            question = content[:500] + "..." if len(content) > 500 else content
        if not correct_answer:
            correct_answer = "ì •ë‹µì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        if not explanation:
            explanation = "í•´ì„¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            
        return question.strip(), correct_answer.strip(), explanation.strip()
        
    except Exception as e:
        print(f"ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return content[:500], "ì •ë‹µì„ í™•ì¸í•´ì£¼ì„¸ìš”.", "í•´ì„¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”."


@router.get("/additional-question-stats")
async def get_additional_question_stats():
    """ì¶”ê°€ ë¬¸ì œ ìƒì„± í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        enhanced_question_service = get_enhanced_local_question_generator_service()
        stats = {
            "total_keywords": len(enhanced_question_service.keywords_data),
            "chapters": enhanced_question_service.chapter_pages,
            "service_type": "local_embedding",
            "openai_dependency": False
        }
        return {
            "success": True,
            "message": "ë¡œì»¬ ì„ë² ë”© í†µê³„ ì¡°íšŒ ì™„ë£Œ",
            "stats": stats
        }
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        ) 