import os
import re
import json
import tempfile
from collections import Counter
import difflib

import fitz  # PyMuPDF
import streamlit as st

# JSON í‚¤ì›Œë“œ ë°ì´í„°
KEYWORDS_DATA = [
    {"word": "ë¬¸ì ì§‘í•©", "pages": [82]},
    {"word": "ë¬¸ìì—´ ê²°í•©", "pages": [55]},
    {"word": "ë¬¸ìì—´ ë¦¬í„°ëŸ´", "pages": [55]},
    {"word": "ë¬¸ìì—´ ë°°ì—´", "pages": [230]},
    {"word": "ë¬¸ìì—´ ë¹„êµ", "pages": [134]},
    {"word": "ë¬¸ìí˜•", "pages": [76]},
    {"word": "ë¬¸ì¥", "pages": [108]},
    {"word": "ë°”ì´íŠ¸", "pages": [65]},
    {"word": "ë°˜ë³µ ìˆœí™˜ íŒ¨í„´", "pages": [184]},
    {"word": "ë°˜ë³µë¬¸", "pages": [180]},
    {"word": "ë°˜í™˜ê°’", "pages": [283]},
    {"word": "ë°˜í™˜íƒ€ì…", "pages": [277]},
    {"word": "ë°°ì—´", "pages": [206]},
    {"word": "ë°°ì—´ ì„ê¸°", "pages": [222]},
    {"word": "ë°°ì—´ ì¹´ìš´íŒ…", "pages": [228]},
    {"word": "ë°°ì—´ì˜ ê¸¸ì´", "pages": [211]},
    {"word": "ë°°ì—´ì˜ ë³µì‚¬", "pages": [216]},
    {"word": "ë°°ì—´ì˜ ìƒì„±", "pages": [207]},
    {"word": "ë°°ì—´ì˜ ìš”ì†Œ", "pages": [208]},
    {"word": "ë°°ì—´ì˜ ì¸ë±ìŠ¤", "pages": [208]},
    {"word": "ë°°ì—´ì˜ ì´ˆê¸°í™”", "pages": [213]},
    {"word": "ë°°ì—´ì˜ ì¶œë ¥", "pages": [214]},
    {"word": "ë²„ë¸” ì •ë ¬", "pages": [226]},
    {"word": "ë²”ìœ„ ì£¼ì„", "pages": [33]},
    {"word": "ë³€ìˆ˜", "pages": [40]},
    {"word": "ë³€ìˆ˜ ê°’êµí™˜", "pages": [43]},
    {"word": "ë³€ìˆ˜ ëª…ëª…ê·œì¹™", "pages": [45]},
    {"word": "ë³€ìˆ˜ ì´ˆê¸°í™”", "pages": [41]},
    {"word": "ë³€ìˆ˜ íƒ€ì…", "pages": [40, 47]},
    {"word": "ìŠ¤íƒ ì˜¤ë²„í”Œë¡œìš°", "pages": [298]},
    {"word": "ì‹(expression)", "pages": [108]},
    {"word": "ì‹ë³„ì", "pages": [45]},
    {"word": "ì‹¤ìˆ˜í˜•", "pages": [89]},
    {"word": "ì‹¤ìˆ˜í˜• ë²”ìœ„", "pages": [89]},
    {"word": "ì‹¤ìˆ˜í˜• ì €ì¥í˜•ì‹", "pages": [92]},
    {"word": "í´ë˜ìŠ¤", "pages": [255]},
    {"word": "ê°ì²´", "pages": [255]},
    {"word": "ë©”ì„œë“œ", "pages": [273]},
    {"word": "ìƒì„±ì", "pages": [315]},
    {"word": "ìƒì†", "pages": [350]},
    {"word": "ë‹¤í˜•ì„±", "pages": [380]},
    {"word": "ìº¡ìŠí™”", "pages": [290]},
    {"word": "ì¸í„°í˜ì´ìŠ¤", "pages": [400]},
    {"word": "ì¶”ìƒí´ë˜ìŠ¤", "pages": [370]},
    {"word": "ì˜ˆì™¸ì²˜ë¦¬", "pages": [450]},
    {"word": "ì»¬ë ‰ì…˜", "pages": [500]},
    {"word": "ì œë„¤ë¦­", "pages": [520]},
    {"word": "ìŠ¤ë ˆë“œ", "pages": [600]},
    {"word": "ëŒë‹¤", "pages": [650]},
    {"word": "ìŠ¤íŠ¸ë¦¼", "pages": [670]}
]

def search_keywords(query, exact_match=False):
    """í‚¤ì›Œë“œ ê²€ìƒ‰ í•¨ìˆ˜"""
    if not query.strip():
        return []
    
    query = query.strip().lower()
    results = []
    
    for item in KEYWORDS_DATA:
        word = item["word"].lower()
        
        if exact_match:
            if word == query:
                results.append(item)
        else:
            if query in word or word in query:
                results.append(item)
    
    # ì •í™•ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    def sort_key(item):
        word = item["word"].lower()
        if word == query:
            return 0
        elif word.startswith(query):
            return 1
        elif word.endswith(query):
            return 2
        else:
            return 3
    
    results.sort(key=sort_key)
    return results

def get_similar_keywords(query, limit=10):
    """ìœ ì‚¬í•œ í‚¤ì›Œë“œ ì¶”ì²œ"""
    if not query.strip():
        return []
    
    query = query.strip().lower()
    similarities = []
    
    for item in KEYWORDS_DATA:
        word = item["word"].lower()
        ratio = difflib.SequenceMatcher(None, query, word).ratio()
        if ratio > 0.3:
            similarities.append((ratio, item))
    
    similarities.sort(key=lambda x: x[0], reverse=True)
    return [item for ratio, item in similarities[:limit]]

def find_pages_for_topic(topic, pages_data):
    """íŠ¹ì • í† í”½ê³¼ ê´€ë ¨ëœ í˜ì´ì§€ ì°¾ê¸°"""
    if not topic.strip() or not pages_data:
        return []
    
    keyword_results = search_keywords(topic)
    related_page_numbers = set()
    
    for result in keyword_results:
        related_page_numbers.update(result["pages"])
    
    related_pages = []
    for page in pages_data:
        if page["page_number"] in related_page_numbers:
            related_pages.append(page)
    
    return sorted(related_pages, key=lambda x: x["page_number"])

def is_figure_or_table_block(text, x0, y0, x1, y1, page_width, page_height):
    """ê·¸ë¦¼ê³¼ í‘œë¥¼ ê°ì§€í•˜ëŠ” í•¨ìˆ˜"""
    text_clean = text.strip().lower()
    
    # í‚¤ì›Œë“œ ê°ì§€
    figure_table_keywords = [
        r'ê·¸ë¦¼\s*\d+', r'í‘œ\s*\d+', r'ë„í‘œ\s*\d+', r'ì°¨íŠ¸\s*\d+',
        r'figure\s*\d+', r'table\s*\d+', r'chart\s*\d+',
        r'<ê·¸ë¦¼\s*\d+>', r'<í‘œ\s*\d+>', r'\[ê·¸ë¦¼\s*\d+\]', r'\[í‘œ\s*\d+\]'
    ]
    
    for pattern in figure_table_keywords:
        if re.search(pattern, text_clean):
            return True, f"í‚¤ì›Œë“œ ê°ì§€: {pattern}"
    
    # í‘œ íŒ¨í„´ ê°ì§€
    lines = text.split('\n')
    table_indicators = 0
    
    for line in lines:
        line_clean = line.strip()
        if not line_clean:
            continue
        
        separators = line_clean.count('|') + line_clean.count('â”€') + line_clean.count('-') * 0.5
        if separators >= 3:
            table_indicators += 1
    
    if table_indicators >= 2:
        return True, f"í‘œ íŒ¨í„´ ê°ì§€: {table_indicators}ê°œ ì§€í‘œ"
    
    # ìœ„ì¹˜ ê¸°ë°˜ ê°ì§€
    block_width = x1 - x0
    block_height = y1 - y0
    center_x = page_width / 2
    center_y = page_height / 2
    block_center_x = (x0 + x1) / 2
    block_center_y = (y0 + y1) / 2
    
    is_center_area = (abs(block_center_x - center_x) < page_width * 0.3 and 
                     abs(block_center_y - center_y) < page_height * 0.3)
    is_small_block = (block_width < page_width * 0.6 and block_height < page_height * 0.2)
    
    if is_center_area and is_small_block and len(text.strip()) < 200:
        return True, f"ì¤‘ì•™ ì˜ì—­ ì‘ì€ ë¸”ë¡"
    
    return False, ""

def extract_text_from_pdf_enhanced(pdf_path):
    """PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    doc = fitz.open(pdf_path)
    pages = []
    total_blocks_removed = 0
    
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        page_rect = page.rect
        page_width = page_rect.width
        page_height = page_rect.height
        
        text_blocks = page.get_text("blocks")
        page_content = []
        page_word_count = 0
        page_blocks_removed = 0

        for i, block in enumerate(text_blocks):
            if len(block) >= 7 and block[6] == 0:  # í…ìŠ¤íŠ¸ ë¸”ë¡ë§Œ
                x0, y0, x1, y1, text, block_no, block_type = block
                
                is_figure_table, reason = is_figure_or_table_block(
                    text, x0, y0, x1, y1, page_width, page_height
                )
                
                if is_figure_table:
                    page_blocks_removed += 1
                    continue
                
                if text.strip():
                    page_content.append(text)
                    page_word_count += len(text.split())
        
        total_blocks_removed += page_blocks_removed
        
        if page_content:
            page_text = "\n".join(page_content)
            page_text = re.sub(r'\n\s*\n\s*\n+', '\n\n', page_text)
            page_text = page_text.strip()
            
            if page_text:
                pages.append({
                    'page_number': page_num + 1,
                    'content': page_text,
                    'word_count': page_word_count,
                    'quality_score': 85  # ê¸°ë³¸ê°’
                })
    
    doc.close()
    return pages, total_blocks_removed

def main():
    st.set_page_config(page_title="Java êµì¬ í‚¤ì›Œë“œ ê²€ìƒ‰ ë„êµ¬", page_icon="â˜•")
    
    st.title("â˜• Java êµì¬ í‚¤ì›Œë“œ ê²€ìƒ‰ ë„êµ¬")
    st.write("PDFì—ì„œ ê·¸ë¦¼/í‘œë¥¼ ì œê±°í•˜ê³  í‚¤ì›Œë“œë¡œ ë¹ ë¥¸ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'filtered_pages' not in st.session_state:
        st.session_state.filtered_pages = None
    if 'filter_keyword' not in st.session_state:
        st.session_state.filter_keyword = None
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ” í‚¤ì›Œë“œ ë¹ ë¥¸ ê²€ìƒ‰")
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ (PDF ì—†ì´ë„ ê°€ëŠ¥)
        search_query = st.text_input("í‚¤ì›Œë“œ ê²€ìƒ‰", placeholder="ì˜ˆ: ë°°ì—´, í´ë˜ìŠ¤, ë©”ì„œë“œ")
        exact_match = st.checkbox("ì •í™•íˆ ì¼ì¹˜", value=False)
        
        if search_query:
            search_results = search_keywords(search_query, exact_match)
            
            if search_results:
                st.success(f"ğŸ” {len(search_results)}ê°œ í‚¤ì›Œë“œ ë°œê²¬")
                
                for result in search_results[:10]:
                    pages_str = ", ".join(map(str, result["pages"]))
                    st.write(f"ğŸ“Œ **{result['word']}**")
                    st.write(f"   í˜ì´ì§€: {pages_str}")
                    st.write("---")
            else:
                st.warning("í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                # ìœ ì‚¬í•œ í‚¤ì›Œë“œ ì¶”ì²œ
                similar = get_similar_keywords(search_query, 5)
                if similar:
                    st.write("ğŸ’¡ **ë¹„ìŠ·í•œ í‚¤ì›Œë“œ:**")
                    for item in similar:
                        if st.button(f"ğŸ”„ {item['word']}", key=f"similar_{item['word']}"):
                            st.session_state.search_query = item['word']
                            st.rerun()
        
        st.divider()
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ
        st.subheader("ğŸ“‚ ì£¼ìš” ì¹´í…Œê³ ë¦¬")
        categories = {
            "ë°°ì—´": ["ë°°ì—´", "ë°°ì—´ì˜ ê¸¸ì´", "ë°°ì—´ì˜ ìƒì„±", "2ì°¨ì› ë°°ì—´"],
            "í´ë˜ìŠ¤": ["í´ë˜ìŠ¤", "ê°ì²´", "ë©”ì„œë“œ", "ìƒì„±ì"],
            "ë³€ìˆ˜": ["ë³€ìˆ˜", "ë³€ìˆ˜ íƒ€ì…", "ë³€ìˆ˜ ì´ˆê¸°í™”"],
            "ì—°ì‚°ì": ["ì‚°ìˆ  ì—°ì‚°ì", "ë¹„êµ ì—°ì‚°ì", "ë…¼ë¦¬ ì—°ì‚°ì"],
            "ì œì–´ë¬¸": ["ë°˜ë³µë¬¸", "ì¡°ê±´ë¬¸", "ë¶„ê¸°ë¬¸"]
        }
        
        for category, keywords in categories.items():
            if st.button(f"ğŸ“ {category}", key=f"cat_{category}"):
                # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  í‚¤ì›Œë“œë¥¼ í‘œì‹œ
                st.session_state.category_view = category

    st.divider()

    # íŒŒì¼ ì—…ë¡œë“œ
    st.subheader("ğŸ“¤ PDF íŒŒì¼ ì—…ë¡œë“œ")
    pdf_file = st.file_uploader("PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type="pdf")

    if pdf_file is not None:
        st.info(f"ğŸ“„ íŒŒì¼ëª…: {pdf_file.name}")
        
        # ì„ì‹œ íŒŒì¼ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(pdf_file.getvalue())
            tmp_file_path = tmp_file.name
        
        try:
            with st.spinner("ğŸ—‘ï¸ PDF ì²˜ë¦¬ ì¤‘..."):
                pages, total_removed = extract_text_from_pdf_enhanced(tmp_file_path)
            
            if not pages:
                st.error("âŒ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

            st.success(f"âœ… ì²˜ë¦¬ ì™„ë£Œ! {len(pages)}ê°œ í˜ì´ì§€, {total_removed}ê°œ ë¸”ë¡ ì œê±°ë¨")
            
            # í‚¤ì›Œë“œ ê²€ìƒ‰ (PDF ì²˜ë¦¬ í›„)
            st.subheader("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰")
            
            col1, col2, col3 = st.columns([3, 1, 1])
            with col1:
                main_search = st.text_input("ê²€ìƒ‰í•  í‚¤ì›Œë“œ", placeholder="ì˜ˆ: ë°°ì—´, ë°˜ë³µë¬¸")
            with col2:
                exact = st.checkbox("ì •í™• ì¼ì¹˜")
            with col3:
                if st.button("ğŸ” ê²€ìƒ‰"):
                    if main_search:
                        results = search_keywords(main_search, exact)
                        if results:
                            related_pages = find_pages_for_topic(main_search, pages)
                            if related_pages:
                                st.session_state.filtered_pages = related_pages
                                st.session_state.filter_keyword = main_search
                                st.success(f"âœ… {len(related_pages)}ê°œ ê´€ë ¨ í˜ì´ì§€ ë°œê²¬!")
                            else:
                                st.warning("í•´ë‹¹ í‚¤ì›Œë“œì˜ í˜ì´ì§€ê°€ PDFì— ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.warning("í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # í•„í„°ë§ëœ í˜ì´ì§€ í‘œì‹œ
            display_pages = st.session_state.filtered_pages if st.session_state.filtered_pages else pages
            filter_keyword = st.session_state.filter_keyword
            
            if filter_keyword:
                st.info(f"ğŸ” '{filter_keyword}' í‚¤ì›Œë“œë¡œ í•„í„°ë§ëœ {len(display_pages)}ê°œ í˜ì´ì§€")
                if st.button("ğŸ”„ ì „ì²´ í˜ì´ì§€ ë³´ê¸°"):
                    st.session_state.filtered_pages = None
                    st.session_state.filter_keyword = None
                    st.rerun()

            # ê²°ê³¼ íƒ­
            tab1, tab2, tab3 = st.tabs(["ğŸ“‹ í˜ì´ì§€ë³„ ë‚´ìš©", "ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸", "ğŸ’¾ ë‹¤ìš´ë¡œë“œ"])
            
            with tab1:
                st.subheader("ğŸ“‹ í˜ì´ì§€ë³„ ë‚´ìš©")
                if filter_keyword:
                    st.info(f"ğŸ” '{filter_keyword}' ê´€ë ¨ í˜ì´ì§€ë§Œ í‘œì‹œ")
                
                for page in display_pages:
                    quality_score = page.get('quality_score', 0)
                    
                    with st.expander(f"ğŸ“„ í˜ì´ì§€ {page['page_number']} (ë‹¨ì–´: {page['word_count']:,}ê°œ)"):
                        # Java íŒŒì¼ ì°¾ê¸°
                        java_files = re.findall(r'\w+\.java\b', page['content'])
                        if java_files:
                            st.success(f"â˜• **Java íŒŒì¼:** {', '.join(set(java_files))}")
                        
                        # ë‚´ìš© í‘œì‹œ
                        content = page['content']
                        if filter_keyword:
                            # ê°„ë‹¨í•œ í•˜ì´ë¼ì´íŠ¸
                            content = re.sub(
                                f"({re.escape(filter_keyword)})", 
                                r"**\1**", 
                                content, 
                                flags=re.IGNORECASE
                            )
                        
                        st.text_area(
                            f"í˜ì´ì§€ {page['page_number']} ë‚´ìš©",
                            content,
                            height=300,
                            key=f"page_{page['page_number']}"
                        )
            
            with tab2:
                st.subheader("ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸")
                full_text = "\n\n".join([
                    f"=== í˜ì´ì§€ {page['page_number']} ===\n{page['content']}"
                    for page in display_pages
                ])
                st.text_area("ì „ì²´ í…ìŠ¤íŠ¸", full_text, height=600)
            
            with tab3:
                st.subheader("ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
                
                full_text_download = "\n\n".join([
                    f"=== í˜ì´ì§€ {page['page_number']} ===\n{page['content']}"
                    for page in display_pages
                ])
                
                filename = f"extracted_text_{pdf_file.name.replace('.pdf', '')}.txt"
                if filter_keyword:
                    filename = f"filtered_{filter_keyword}_{pdf_file.name.replace('.pdf', '')}.txt"
                
                st.download_button(
                    label="ğŸ“¥ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
                    data=full_text_download,
                    file_name=filename,
                    mime="text/plain"
                )
                
                st.write(f"- **ì´ í˜ì´ì§€:** {len(display_pages)}ê°œ")
                st.write(f"- **ì´ ë‹¨ì–´:** {sum(page['word_count'] for page in display_pages):,}ê°œ")
                if filter_keyword:
                    st.write(f"- **í•„í„° í‚¤ì›Œë“œ:** {filter_keyword}")

        except Exception as e:
            st.error(f"âŒ ì˜¤ë¥˜: {e}")
            
        finally:
            if os.path.exists(tmp_file_path):
                os.remove(tmp_file_path)

    else:
        # PDF ì—†ì´ë„ í‚¤ì›Œë“œ ê²€ìƒ‰ ê°€ëŠ¥
        st.subheader("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ (PDF ì—†ì´)")
        st.write("PDFë¥¼ ì—…ë¡œë“œí•˜ì§€ ì•Šì•„ë„ í‚¤ì›Œë“œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        # ì „ì²´ í‚¤ì›Œë“œ ëª©ë¡
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ğŸ“‚ ì£¼ìš” í‚¤ì›Œë“œ:**")
            main_keywords = ["ë°°ì—´", "í´ë˜ìŠ¤", "ë©”ì„œë“œ", "ë³€ìˆ˜", "ë°˜ë³µë¬¸", "ì¡°ê±´ë¬¸", "ìƒì„±ì", "ìƒì†"]
            for keyword in main_keywords:
                result = search_keywords(keyword, exact_match=True)
                if result:
                    pages_str = ", ".join(map(str, result[0]["pages"]))
                    st.write(f"â€¢ **{keyword}** â†’ í˜ì´ì§€: {pages_str}")
        
        with col2:
            st.write("**ğŸ” ê²€ìƒ‰ ì˜ˆì‹œ:**")
            st.code("""
            "ë°°ì—´" â†’ ë°°ì—´ ê´€ë ¨ í‚¤ì›Œë“œ 15ê°œ
            "í´ë˜ìŠ¤" â†’ í´ë˜ìŠ¤ ê´€ë ¨ í‚¤ì›Œë“œ 8ê°œ  
            "ë©”ì„œë“œ" â†’ ë©”ì„œë“œ ê´€ë ¨ í‚¤ì›Œë“œ 6ê°œ
            "ë³€ìˆ˜" â†’ ë³€ìˆ˜ ê´€ë ¨ í‚¤ì›Œë“œ 10ê°œ
            """)

if __name__ == '__main__':
    main()