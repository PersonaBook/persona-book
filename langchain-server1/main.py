"""
ğŸš€ ìƒíƒœ ë¨¸ì‹  ê¸°ë°˜ Java Learning Chat System
ChatState enumì„ ì‚¬ìš©í•œ ìƒíƒœ ê´€ë¦¬ì™€ FastAPI í˜¸ì¶œì„ í†µí•œ ê¸°ëŠ¥ ì²˜ë¦¬
"""

import os
import sys
import json
from typing import List, Dict, Any, Optional
from pathlib import Path

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv("../.env")  # ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ .env íŒŒì¼ ë¡œë“œ

# LangChain ê´€ë ¨ ì„í¬íŠ¸
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_experimental.text_splitter import SemanticChunker

# PyMuPDF ë° í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ê´€ë ¨ ì„í¬íŠ¸
import fitz  # PyMuPDF
import re
import json

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from core.state_machine import ChatState, StateMachine, FastAPIClient
from core.models import ModelManager
from core.vector_store import VectorStoreManager
from core.chains import ChainFactory
from core.concept_explainer import ConceptExplainer
from utils.file_manager import ConfigManager, KeywordManager, AnswerHistoryManager
from generators.question_generator import QuestionGenerator
from analyzers.adaptive_learning import WeaknessAnalyzer, QuestionQualityAnalyzer

def clean_java_text(text: str) -> str:
    """
    OCR ê³¼ì •ì—ì„œ ê¹¨ì§€ê¸° ì‰¬ìš´ Java ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ ì •ê·œì‹ì„ ì‚¬ìš©í•´ ë³µì›í•©ë‹ˆë‹¤.
    """
    patterns = [
        # 1. ì˜ˆì œ ë²ˆí˜¸ ë³µì› (â–¼ ê¸°í˜¸ ìœ ë¬´ì— ê´€ê³„ì—†ì´ ì²˜ë¦¬)
        (r'â–¼?\s*ì˜ˆì œ\s+(\d+)\s*-\s*(\d+)\s*/\s*(\w+)\s*\.\s*j(?:ava)?\s*(?=[^\w]|$)', r'â–¼ ì˜ˆì œ \1-\2/\3.java'),
        
        # 2. 'FileName.java'ì™€ ê°™ì€ íŒŒì¼ëª… íŒ¨í„´ ë³µì›
        (r'(\w+)\s*\.\s*j(?:ava)?\s*(?=[^\w]|$)', r'\1.java'),
        
        # 3. 'ClassEx.java', 'ClassTest.java' ê°™ì€ í´ë˜ìŠ¤ëª… ë³µì›
        (r'(\w+(?:Ex|Test))\s*\.\s*j(?:ava)?\s*(?=[^\w]|$)', r'\1.java'),
        
        # 4. 'java.util', 'java.io' ê°™ì€ íŒ¨í‚¤ì§€ëª… ë³µì›
        (r'\b(j)\s*\.\s*(util|io|awt)\b', r'java.\2'),
        
        # 5. 'Java API' ê°™ì€ API ê´€ë ¨ ìš©ì–´ ë³µì›
        (r'\bJava\s+A\s*P\s*I\b', r'Java API'),
        
        # 6. System.out.print/println êµ¬ë¬¸ ë³µì›
        (r'System\s*\.\s*o[u\s]*t\s*\.\s*print(ln)?', r'System.out.print\1'),
        
        # 7. Java ê¸°ë³¸ íƒ€ì… í‚¤ì›Œë“œ ë³µì›
        (r'\b[fF]+[oOaA]*[tT]+\b', r'float'),
        (r'\b[iI]+[nN]*[tT]+\b', r'int'),
        (r'\b[dD]+[oO]*[uU]+[bB]+[lL]+[eE]+\b', r'double'),
        (r'\b[cC]+[hH]*[aA]+[rR]+\b', r'char'),
        (r'\b[bB]+[oO]*[lL]+[eEaA]*[nN]+\b', r'boolean'),
    ]
    
    cleaned = text
    for pattern, replacement in patterns:
        try:
            cleaned = re.sub(pattern, replacement, cleaned, flags=re.IGNORECASE)
        except re.error as e:
            print(f"Regex error for pattern '{pattern}': {e}")
            continue
    
    return cleaned

def remove_ebook_sample_text(text: str) -> str:
    """
    PDFì— í¬í•¨ëœ eBook ìƒ˜í”Œ ê´€ë ¨ ìƒìš©êµ¬ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    """
    patterns = [
        r"[ebook.*?ìƒ˜í”Œ.*?ë¬´ë£Œ.*?ê³µìœ ].*?seong\.namkung@gmail\.com",
        r"seong\.namkung@gmail\.com",
        r"2025\.\s*7\.\s*7\s*ì¶œì‹œ",
        r"ì˜¬ì»¬ëŸ¬.*?2025",
    ]
    
    cleaned_text = text
    for pattern in patterns:
        cleaned_text = re.sub(pattern, "", cleaned_text, flags=re.IGNORECASE | re.DOTALL)
    
    return cleaned_text

class JavaTextbookCleaner:
    """
    Java êµì¬ PDFì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ì •ì œí•˜ëŠ” í´ë˜ìŠ¤.
    """
    def __init__(self):
        # ì œê±°í•  ë¼ì¸ íŒ¨í„´
        self.remove_line_patterns = [
            r'^\s*[\|\-\+\s]+$',
            r'^\s*[\d\s\.\,\|\-]+\s*$',
            r'^\s*Chapter\s+\d+\s*$',
            r'^\s*[><]?\s*\d+\s*[><]?$',
        ]
        # í‘œì˜ ë‚´ìš©ìœ¼ë¡œ íŒë‹¨ë˜ëŠ” í‚¤ì›Œë“œ íŒ¨í„´
        self.table_content_patterns = [
            r'ì¢…\s*ë¥˜.*?ì—°ì‚°ì.*?ìš°ì„ ìˆœìœ„',
            r'ê²°í•©ê·œì¹™.*?ì—°ì‚°ì',
            r'ìš°ì„ ìˆœìœ„.*?ë†’ìŒ.*?ë‚®ìŒ',
        ]

    def clean_line(self, line: str) -> str:
        """ë¼ì¸ë³„ë¡œ ë¶ˆí•„ìš”í•œ ë‚´ìš©ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
        line = line.strip()
        if not line:
            return ""
        
        # ë” ê´€ëŒ€í•œ ì¡°ê±´: 2ê¸€ì ì´ìƒì´ë©´ ìœ ì§€
        if len(line) < 2:
            return ""
        
        for pattern in self.remove_line_patterns:
            if re.match(pattern, line):
                return ""
        
        # íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ë¼ì¸ ì œê±° (ë” ê´€ëŒ€í•˜ê²Œ)
        if re.match(r'^[^\w\sê°€-í£]+$', line) and len(line) < 5:
            return ""
        
        return line

    def is_code_block(self, text: str) -> bool:
        """Java ì½”ë“œ ë¸”ë¡ì¸ì§€ ì¶”ì •í•©ë‹ˆë‹¤."""
        code_indicators = ['class ', 'public ', 'static ', 'void ', 'import ', '//', '/*', '{', '}', ';']
        return any(indicator in text for indicator in code_indicators)

    def is_table_block(self, lines: list[str]) -> bool:
        """ì—¬ëŸ¬ ì¤„ë¡œ êµ¬ì„±ëœ í…ìŠ¤íŠ¸ ë¸”ë¡ì´ í‘œì¸ì§€ ì¶”ì •í•©ë‹ˆë‹¤."""
        if len(lines) < 2:
            return False
        
        full_text = '\n'.join(lines)
        for pattern in self.table_content_patterns:
            if re.search(pattern, full_text, re.DOTALL):
                return True
        
        # ëŒ€ë¶€ë¶„ì˜ ë¼ì¸ì´ ì§§ê³ (70% ì´ìƒ), ìˆ«ì í¬í•¨ ë¼ì¸ì´ ì ˆë°˜ ì´ìƒì´ë©´ í‘œë¡œ ê°„ì£¼
        short_lines = sum(1 for line in lines if len(line.strip()) < 20)
        numeric_lines = sum(1 for line in lines if re.search(r'\d', line))
        if len(lines) > 0 and short_lines / len(lines) > 0.7 and numeric_lines / len(lines) > 0.5:
            return True
        
        return False

    def is_valid_content_block(self, block_text: str) -> bool:
        """ìœ íš¨í•œ ì½˜í…ì¸ (ì½”ë“œ ë˜ëŠ” ì„¤ëª…)ë¥¼ ë‹´ê³  ìˆëŠ” í…ìŠ¤íŠ¸ ë¸”ë¡ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
        if not block_text.strip():
            return False
        
        lines = block_text.split('\n')
        if self.is_table_block(lines):
            return False
        
        # ë” ê´€ëŒ€í•œ ì¡°ê±´: í•œê¸€ì´ ìˆê±°ë‚˜, ì½”ë“œì˜ ì¼ë¶€ì´ê±°ë‚˜, ì˜ì–´ ë¬¸ì¥ì´ ìˆìœ¼ë©´ ìœ íš¨í•œ ë¸”ë¡ìœ¼ë¡œ ê°„ì£¼
        if re.search(r'[ê°€-í£]', block_text) or self.is_code_block(block_text):
            return True
        
        # ì˜ì–´ ë¬¸ì¥ì´ ìˆëŠ”ì§€ í™•ì¸ (ë” ê´€ëŒ€í•˜ê²Œ)
        sentences = re.split(r'[.!?]', block_text)
        return any(len(s.strip()) > 5 for s in sentences if s.strip())

def sort_blocks_by_reading_order(text_blocks: list) -> list:
    """PyMuPDF í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ì½ê¸° ìˆœì„œ(ìœ„->ì•„ë˜, ì™¼ìª½->ì˜¤ë¥¸ìª½)ë¡œ ì •ë ¬í•©ë‹ˆë‹¤."""
    # í…ìŠ¤íŠ¸ ë¸”ë¡(type=0)ë§Œ í•„í„°ë§
    text_only_blocks = [b for b in text_blocks if b[6] == 0]
    # yì¢Œí‘œ(b[1]) ìš°ì„ , ê°™ì€ ë¼ì¸ì´ë©´ xì¢Œí‘œ(b[0]) ìˆœìœ¼ë¡œ ì •ë ¬
    return sorted(text_only_blocks, key=lambda b: (b[1], b[0]))

def extract_preprocessed_pdf_text(pdf_path: str) -> list[dict]:
    """
    PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        pdf_path: ì²˜ë¦¬í•  PDF íŒŒì¼ì˜ ê²½ë¡œ

    Returns:
        í˜ì´ì§€ë³„ë¡œ ì •ë¦¬ëœ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    cleaner = JavaTextbookCleaner()
    pages_content = []

    with fitz.open(pdf_path) as doc:
        for page_num, page in enumerate(doc, 1):
            text_blocks = page.get_text("blocks")
            sorted_blocks = sort_blocks_by_reading_order(text_blocks)
            
            page_content = []
            for block in sorted_blocks:
                block_text = block[4]
                if cleaner.is_valid_content_block(block_text):
                    cleaned_lines = [cleaner.clean_line(line) for line in block_text.splitlines()]
                    cleaned_block = '\n'.join(filter(None, cleaned_lines))
                    if cleaned_block:
                        # OCR ì˜¤ë¥˜ ìˆ˜ì • ì ìš©
                        corrected_text = clean_java_text(cleaned_block)
                        # eBook ìƒ˜í”Œ í…ìŠ¤íŠ¸ ì œê±°
                        final_text = remove_ebook_sample_text(corrected_text)
                        page_content.append(final_text)
            
            if page_content:
                full_text = "\n\n".join(page_content)
                pages_content.append({
                    'page_number': page_num,
                    'content': full_text,
                    'word_count': len(full_text.split())
                })
    
    return pages_content

class JavaLearningSystem:
    """Java í•™ìŠµ ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        print("ğŸš€ **ìƒíƒœ ë¨¸ì‹  ê¸°ë°˜ Java Learning Chat System**")
        print("="*60)
        
        # ì„¤ì • ë° ë°ì´í„° ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.config_manager = ConfigManager()
        self.keyword_manager = KeywordManager()
        self.answer_history_manager = AnswerHistoryManager()
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤
        self.model_manager = ModelManager()
        self.vector_store_manager = None
        self.chain_manager = None
        self.chain_executor = None
        
        # ìƒì„±ê¸° ë° ë¶„ì„ê¸°ë“¤
        self.question_generator = None
        self.weakness_analyzer = None
        self.quality_analyzer = None
        
        # ìƒíƒœ ë¨¸ì‹  ë° FastAPI í´ë¼ì´ì–¸íŠ¸
        self.state_machine = StateMachine()
        self.fastapi_client = FastAPIClient()
        
        # ê°œë… ì„¤ëª…ê¸°
        self.concept_explainer = None
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.is_initialized = False
        
        # í‚¤ì›Œë“œ ë°ì´í„° ë¡œë“œ
        self.keywords_data = self._load_keywords()
        
        # ì±•í„°ë³„ í˜ì´ì§€ ë²”ìœ„ ì •ì˜ (1ë¶€í„° ì‹œì‘)
        self.chapter_pages = {
            "Chapter1 - ë³€ìˆ˜": (30, 107),
            "Chapter2 - ì—°ì‚°ì": (108, 157),
            "Chapter3 - ì¡°ê±´ë¬¸ê³¼ ë°˜ë³µë¬¸": (158, 205),
            "Chapter4 - ë°°ì—´": (206, 253),
            "Chapter5 - ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° I": (254, 339)
        }
    
    def _load_keywords(self) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            keywords_file = "keywords.json"
            if os.path.exists(keywords_file):
                with open(keywords_file, 'r', encoding='utf-8') as f:
                    keywords = json.load(f)
                print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ: keywords.json ({len(keywords)}ê°œ í‚¤ì›Œë“œ)")
                return keywords
            else:
                # ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
                parent_keywords = "../langchain-server/ëŒ€í™”í…ŒìŠ¤íŠ¸/keywords.json"
                if os.path.exists(parent_keywords):
                    with open(parent_keywords, 'r', encoding='utf-8') as f:
                        keywords = json.load(f)
                    print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ: {parent_keywords} ({len(keywords)}ê°œ í‚¤ì›Œë“œ)")
                    return keywords
                else:
                    print("ğŸ“‚ íŒŒì¼ ì—†ìŒ: keywords.json (ê¸°ë³¸ê°’ ì‚¬ìš©)")
                    return []
        except Exception as e:
            print(f"âš ï¸ í‚¤ì›Œë“œ ë¡œë”© ì˜¤ë¥˜: {e}")
            return []
    
    def initialize_system(self) -> bool:
        """ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        print("\nğŸ”§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # 1. AI ëª¨ë¸ ì´ˆê¸°í™”
        if not self.model_manager.initialize_models():
            return False
        
        # 2. PDF ê²½ë¡œ ì„¤ì •
        pdf_path = self._get_pdf_path()
        if not pdf_path:
            print("âš ï¸ PDF íŒŒì¼ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        # 3. PDF ë° ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •
        if not self._setup_vector_store(pdf_path):
            return False
        
        # 4. ì²´ì¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_chains()
        
        # 5. ìƒì„±ê¸° ë° ë¶„ì„ê¸° ì´ˆê¸°í™”
        self._initialize_generators()
        self._initialize_analyzers()
        
        # 6. ê°œë… ì„¤ëª…ê¸° ì´ˆê¸°í™”
        self.concept_explainer = ConceptExplainer(self.chain_executor, self.vector_store_manager)
        
        self.is_initialized = True
        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        return True
    
    def _get_pdf_path(self) -> Optional[str]:
        """PDF ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        # 1. config.jsonì—ì„œ ì„¤ì •ëœ ê²½ë¡œ í™•ì¸
        config_path = self.config_manager.get("pdf_path")
        if config_path and os.path.exists(config_path):
            return config_path
        
        # 2. í™˜ê²½ë³€ìˆ˜ì—ì„œ í™•ì¸
        env_path = os.environ.get("JAVA_PDF_PATH")
        if env_path and os.path.exists(env_path):
            return env_path
        
        # 3. ê¸°ë³¸ ìœ„ì¹˜ë“¤ í™•ì¸
        default_paths = [
            "javajungsuk4_sample.pdf",
            "../javajungsuk4_sample.pdf",
            "./data/javajungsuk4_sample.pdf",
            "../data/javajungsuk4_sample.pdf",
            "../langchain-server/ëŒ€í™”í…ŒìŠ¤íŠ¸/data/javajungsuk4_sample.pdf",
            "../ai/javajungsuk4_sample.pdf"
        ]
        
        for path in default_paths:
            if os.path.exists(path):
                return path
        
        return "/Users/david/Documents/study/KDT_BE12_Toy_Project/ai/javajungsuk4_sample.pdf"
    
    def _setup_vector_store(self, pdf_path: str) -> bool:
        """ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
        try:
            print("ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì „ì²˜ë¦¬ ì‹œì‘...")
            
            # PyMuPDFë¥¼ ì‚¬ìš©í•œ ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            pages_content = extract_preprocessed_pdf_text(pdf_path)
            
            if not pages_content:
                print("âŒ PDFì—ì„œ ìœ íš¨í•œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return False
            
            print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! {len(pages_content)}ê°œ í˜ì´ì§€")
            
            # LangChain Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            from langchain.schema import Document
            documents = []
            
            for page in pages_content:
                doc = Document(
                    page_content=page['content'],
                    metadata={
                        'page_number': page['page_number'],
                        'word_count': page['word_count'],
                        'source': pdf_path
                    }
                )
                documents.append(doc)
            
            # í…ìŠ¤íŠ¸ ë¶„í•  (ë” ì‘ì€ ì²­í¬ë¡œ ë¶„í• )
            # ì˜¬ë°”ë¥¸ ì„¤ì •
            text_splitter = SemanticChunker(
                self.model_manager.get_embeddings(),
                breakpoint_threshold_type="percentile",
                breakpoint_threshold_amount=95
            )
            chunks = text_splitter.split_documents(documents)
            
            # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
            self.vector_store_manager = VectorStoreManager(self.model_manager.get_embeddings())
            success = self.vector_store_manager.setup_vector_store(chunks, pdf_path)
            
            if success:
                print(f"âœ… ë²¡í„° ìŠ¤í† ì–´ ì„¤ì • ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬")
                print(f"   - ì›ë³¸ í˜ì´ì§€: {len(pages_content)}ê°œ")
                print(f"   - ì´ ë‹¨ì–´ ìˆ˜: {sum(page['word_count'] for page in pages_content)}ê°œ")
                return True
            else:
                return False
                
        except Exception as e:
            print(f"âŒ ë²¡í„° ìŠ¤í† ì–´ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    def _initialize_chains(self):
        """ì²´ì¸ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        retriever = self.vector_store_manager.get_retriever(
            k=self.config_manager.get("vector_store_k", 5)
        )
        
        self.chain_manager, self.chain_executor = ChainFactory.create_complete_chain_system(
            llm=self.model_manager.get_llm(),
            retriever=retriever
        )
    
    def _initialize_generators(self):
        """ìƒì„±ê¸°ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        # retriever ê°€ì ¸ì˜¤ê¸°
        retriever = self.vector_store_manager.get_retriever()
        self.question_generator = QuestionGenerator(self.model_manager.get_llm(), retriever)
    
    def _initialize_analyzers(self):
        """ë¶„ì„ê¸°ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.weakness_analyzer = WeaknessAnalyzer(self.chain_executor)
        self.quality_analyzer = QuestionQualityAnalyzer(self.chain_executor)
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        if not self.is_initialized:
            if not self.initialize_system():
                print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
                return
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        self.state_machine.transition_to(ChatState.WAITING_USER_SELECT_FEATURE)
        
        while True:
            try:
                # í˜„ì¬ ìƒíƒœì— ë”°ë¥¸ ì²˜ë¦¬
                current_state = self.state_machine.current_state
                
                if current_state == ChatState.WAITING_USER_SELECT_FEATURE:
                    self._handle_feature_selection()
                elif current_state == ChatState.WAITING_PROBLEM_CRITERIA_SELECTION:
                    self._handle_problem_criteria_selection()
                elif current_state == ChatState.WAITING_PROBLEM_CONTEXT_INPUT:
                    self._handle_problem_context_input()
                elif current_state == ChatState.WAITING_USER_ANSWER:
                    self._handle_user_answer()
                elif current_state == ChatState.WAITING_CONCEPT_INPUT:
                    self._handle_concept_input()
                elif current_state == ChatState.WAITING_CONCEPT_RATING:
                    self._handle_concept_rating()
                elif current_state == ChatState.WAITING_REASON_FOR_LOW_RATING:
                    self._handle_low_rating_reason()
                elif current_state == ChatState.WAITING_KEYWORD_FOR_PAGE_SEARCH:
                    self._handle_page_search_keyword()
                elif current_state == ChatState.WAITING_NEXT_ACTION_AFTER_LEARNING:
                    self._handle_next_action_after_learning()
                else:
                    print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ: {current_state}")
                    self.state_machine.transition_to(ChatState.WAITING_USER_SELECT_FEATURE)
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                self.state_machine.transition_to(ChatState.WAITING_USER_SELECT_FEATURE)
    
    def _handle_feature_selection(self):
        """ê¸°ëŠ¥ ì„ íƒì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        print("\n" + "="*60)
        print("ğŸ¯ **Java í•™ìŠµ ì‹œìŠ¤í…œ**")
        print("="*60)
        print("1ï¸âƒ£  ì˜ˆìƒë¬¸ì œ ìƒì„±")
        print("2ï¸âƒ£  í•™ìŠµë³´ì¶© (ê°œë… ì„¤ëª…)")
        print("3ï¸âƒ£  í˜ì´ì§€ ì°¾ê¸°")
        print("0ï¸âƒ£  ì¢…ë£Œ")
        print("="*60)
        
        choice = input("\nì„ íƒí•˜ì„¸ìš”: ").strip()
        
        if choice == '1':
            self.state_machine.transition_to(ChatState.WAITING_PROBLEM_CRITERIA_SELECTION)
            print("ğŸ¤– ì‹œìŠ¤í…œ: ë¬¸ì œ ìƒì„±ì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤. ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ë¬¸ì œë¥¼ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
            print("1. ì±•í„°/í˜ì´ì§€ ì„ íƒ")
            print("2. íŠ¹ì • ê°œë… ì„ íƒ")
        elif choice == '2':
            self.state_machine.transition_to(ChatState.WAITING_CONCEPT_INPUT)
            print("ğŸ¤– ì‹œìŠ¤í…œ: í•™ìŠµë³´ì¶©ì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤. ì„¤ëª…ì„ ì›í•˜ëŠ” ê°œë…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif choice == '3':
            self.state_machine.transition_to(ChatState.WAITING_KEYWORD_FOR_PAGE_SEARCH)
            print("ğŸ¤– ì‹œìŠ¤í…œ: í˜ì´ì§€ ì°¾ê¸°ë¥¼ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤. ì°¾ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif choice == '0':
            print("ğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            sys.exit(0)
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1-3, 0 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    def _handle_problem_criteria_selection(self):
        """ë¬¸ì œ ìƒì„± ê¸°ì¤€ ì„ íƒì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        choice = input("\nì„ íƒí•˜ì„¸ìš”: ").strip()
        
        if choice == '1':
            self.state_machine.transition_to(ChatState.WAITING_PROBLEM_CONTEXT_INPUT)
            print("ğŸ¤– ì‹œìŠ¤í…œ: ì±•í„°/í˜ì´ì§€ ì„ íƒì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤. ì±•í„°ëª… ë˜ëŠ” í˜ì´ì§€ ë²”ìœ„ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            print("ì˜ˆì‹œ: Chapter1 - ë³€ìˆ˜, 30-50í˜ì´ì§€")
        elif choice == '2':
            self.state_machine.transition_to(ChatState.WAITING_PROBLEM_CONTEXT_INPUT)
            print("ğŸ¤– ì‹œìŠ¤í…œ: íŠ¹ì • ê°œë… ì„ íƒì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤. ë¬¸ì œë¥¼ ìƒì„±í•  ê°œë…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
    
    def _handle_problem_context_input(self):
        """ë¬¸ì œ ì»¨í…ìŠ¤íŠ¸ ì…ë ¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        user_input = input("\nì…ë ¥í•´ì£¼ì„¸ìš”: ").strip()
        
        if not user_input:
            print("âŒ ì…ë ¥ì„ í•´ì£¼ì„¸ìš”.")
            return
        
        # ì…ë ¥ ê²€ì¦ ë° ë§¤í•‘
        processed_input = self._process_user_input(user_input)
        if not processed_input:
            print("âŒ ì˜¬ë°”ë¥¸ ì±•í„°ëª…ì´ë‚˜ ê°œë…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        # ìƒíƒœ ì „í™˜
        self.state_machine.transition_to(ChatState.GENERATING_QUESTION_WITH_RAG)
        
        # FastAPI í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        print("ğŸ” FastAPI í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜: RAG ê¸°ë°˜ ë¬¸ì œ ìƒì„±")
        print(f"   - Context: {processed_input}")
        
        # ë¬¸ì œ ìƒì„±
        question = self.question_generator.generate_question(processed_input)
        
        if question:
            # ìƒíƒœ ì „í™˜
            self.state_machine.transition_to(ChatState.QUESTION_PRESENTED_TO_USER)
            
            # ë¬¸ì œ í‘œì‹œ
            print(f"\nğŸ¤– ì‹œìŠ¤í…œ: ë¬¸ì œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤ (í’ˆì§ˆ: {question.get('quality_score', 0.5)}):")
            print(f"{question['question']}")
            for i, option in enumerate(question['options'], 1):
                print(f"{i}. {option}")
            print("ì •ë‹µì„ ì„ íƒí•´ì£¼ì„¸ìš” (1-4):")
            
            # ì»¨í…ìŠ¤íŠ¸ ì €ì¥
            self.state_machine.update_context("current_question", question)
            self.state_machine.update_context("previous_topic", user_input)
            
            # ìƒíƒœ ì „í™˜
            self.state_machine.transition_to(ChatState.WAITING_USER_ANSWER)
        else:
            print("âŒ ë¬¸ì œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            self.state_machine.transition_to(ChatState.WAITING_PROBLEM_CONTEXT_INPUT)
    
    def _handle_user_answer(self):
        """ì‚¬ìš©ì ë‹µë³€ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        try:
            user_answer = int(input("\nì…ë ¥í•´ì£¼ì„¸ìš”: ").strip())
            
            if 1 <= user_answer <= 4:
                # ìƒíƒœ ì „í™˜
                self.state_machine.transition_to(ChatState.EVALUATING_ANSWER_AND_LOGGING)
                
                # í˜„ì¬ ë¬¸ì œ ê°€ì ¸ì˜¤ê¸°
                current_question = self.state_machine.get_context("current_question")
                if not current_question:
                    print("âŒ ë¬¸ì œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    self.state_machine.transition_to(ChatState.WAITING_USER_SELECT_FEATURE)
                    return
                
                # ë‹µë³€ í‰ê°€
                correct_answer = current_question.get('correct_answer', 1)
                is_correct = (user_answer == correct_answer)
                
                if is_correct:
                    print("ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤!")
                    self.state_machine.transition_to(ChatState.WAITING_NEXT_ACTION_AFTER_LEARNING)
                else:
                    print(f"âŒ í‹€ë ¸ìŠµë‹ˆë‹¤. ì •ë‹µì€ {correct_answer}ë²ˆì…ë‹ˆë‹¤.")
                    print(f"ğŸ“– **ì„¤ëª…:** {current_question.get('explanation', '')}")
                    
                    # ì˜¤ë‹µ ì‹œ ê°œë… ì„¤ëª…
                    self.state_machine.transition_to(ChatState.PRESENTING_CONCEPT_EXPLANATION)
                    
                    # ë¬¸ì œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
                    concept_keyword = self._extract_primary_keyword_from_question(current_question)
                    print(f"\nğŸ“š **{concept_keyword} ê°œë… ì„¤ëª…**")
                    print("="*40)
                    
                    # êµ¬ì²´ì ì¸ ê°œë… ì„¤ëª… ìƒì„±
                    explanation = self.concept_explainer.explain_concept(concept_keyword)
                    
                    if explanation:
                        print(f"\nğŸ“š **{concept_keyword} ê°œë… ì„¤ëª…**")
                        print("="*40)
                        print(explanation)
                    
                    self.state_machine.transition_to(ChatState.WAITING_CONCEPT_RATING)
                    print("\nì„¤ëª…ì´ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”? (1-5ì ):")
            else:
                print("âŒ 1-4 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("âŒ ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    def _handle_concept_input(self):
        """ê°œë… ì…ë ¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        concept = input("\nì…ë ¥í•´ì£¼ì„¸ìš”: ").strip()
        
        if not concept:
            print("âŒ ê°œë…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        # ìƒíƒœ ì „í™˜
        self.state_machine.transition_to(ChatState.PRESENTING_CONCEPT_EXPLANATION)
        
        # ê°œë… ì„¤ëª… ìƒì„±
        explanation = self.concept_explainer.explain_concept(concept)
        
        if explanation:
            print(f"\nğŸ“š **{concept} ê°œë… ì„¤ëª…**")
            print("="*40)
            print(explanation)
            
            # ìƒíƒœ ì „í™˜
            self.state_machine.transition_to(ChatState.WAITING_CONCEPT_RATING)
            print("\nì„¤ëª…ì´ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”? (1-5ì ):")
        else:
            print("âŒ ê°œë… ì„¤ëª… ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            self.state_machine.transition_to(ChatState.WAITING_USER_SELECT_FEATURE)
    
    def _handle_concept_rating(self):
        """ê°œë… ì„¤ëª… í‰ê°€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        try:
            rating = int(input("\nì…ë ¥í•´ì£¼ì„¸ìš”: ").strip())
            
            if 1 <= rating <= 5:
                if rating <= 3:
                    # ë‚®ì€ í‰ê°€ ì‹œ ì´ìœ  ìš”ì²­
                    self.state_machine.transition_to(ChatState.WAITING_REASON_FOR_LOW_RATING)
                    print("ë” ë‚˜ì€ ì„¤ëª…ì„ ìœ„í•´ ì–´ë–¤ ë¶€ë¶„ì´ ë¶€ì¡±í–ˆëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.")
                else:
                    # ë†’ì€ í‰ê°€ ì‹œ ë‹¤ìŒ ì•¡ì…˜
                    print("ì„¤ëª…ì´ ë„ì›€ì´ ë˜ì—ˆë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤!")
                    self.state_machine.transition_to(ChatState.WAITING_NEXT_ACTION_AFTER_LEARNING)
            else:
                print("âŒ 1-5 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("âŒ ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    def _handle_low_rating_reason(self):
        """ë‚®ì€ í‰ê°€ ì´ìœ ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        reason = input("\nì…ë ¥í•´ì£¼ì„¸ìš”: ").strip()
        
        if not reason:
            print("âŒ ì´ìœ ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        # ìƒíƒœ ì „í™˜
        self.state_machine.transition_to(ChatState.REEXPLAINING_CONCEPT)
        
        # ì¬ì„¤ëª… ìƒì„±
        concept_keyword = self.state_machine.get_context("current_concept", "Java")
        reexplanation = self.concept_explainer.reexplain_concept(concept_keyword, reason)
        
        if reexplanation:
            print(f"\nğŸ“– **ë³´ì¶© ì„¤ëª…**")
            print("="*40)
            print(f"ğŸ” **ì‚¬ìš©ì í”¼ë“œë°±:** {reason}")
            print("\nğŸ“– **ê°œì„ ëœ ì„¤ëª…:**")
            print(reexplanation)
            
            # ìƒíƒœ ì „í™˜
            self.state_machine.transition_to(ChatState.WAITING_CONCEPT_RATING)
            print("\nì´ ì„¤ëª…ì´ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”? (1-5ì ):")
        else:
            print("âŒ ì¬ì„¤ëª… ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            self.state_machine.transition_to(ChatState.WAITING_USER_SELECT_FEATURE)
    
    def _handle_page_search_keyword(self):
        """í˜ì´ì§€ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        keyword = input("\nì…ë ¥í•´ì£¼ì„¸ìš”: ").strip()
        
        if not keyword:
            print("âŒ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        # ìƒíƒœ ì „í™˜
        self.state_machine.transition_to(ChatState.PROCESSING_PAGE_SEARCH_RESULT)
        
        # í˜ì´ì§€ ê²€ìƒ‰
        search_results = self._search_pages_by_keyword(keyword)
        
        if search_results:
            print(f"\nğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼ ({len(search_results)}ê°œ):")
            for i, result in enumerate(search_results, 1):
                print(f"  {i}. {result}")
        else:
            print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìƒíƒœ ì „í™˜
        self.state_machine.transition_to(ChatState.WAITING_USER_SELECT_FEATURE)
    
    def _handle_next_action_after_learning(self):
        """í•™ìŠµ í›„ ë‹¤ìŒ ì•¡ì…˜ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        print("\në‹¤ìŒ ì¤‘ ì„ íƒí•´ì£¼ì„¸ìš”:")
        print("1. ë‹¤ìŒ ë¬¸ì œ í’€ê¸°")
        print("2. ë‹¤ë¥¸ ê¸°ëŠ¥ìœ¼ë¡œ ëŒì•„ê°€ê¸°")
        
        choice = input("\nì„ íƒí•˜ì„¸ìš”: ").strip()
        
        if choice == '1':
            # ì´ì „ í† í”½ìœ¼ë¡œ ë¬¸ì œ ìƒì„±
            previous_topic = self.state_machine.get_context("previous_topic")
            if previous_topic:
                self.state_machine.transition_to(ChatState.WAITING_PROBLEM_CONTEXT_INPUT)
                print(f"ğŸ¤– ì‹œìŠ¤í…œ: '{previous_topic}'ì— ëŒ€í•œ ë‹¤ìŒ ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            else:
                self.state_machine.transition_to(ChatState.WAITING_PROBLEM_CONTEXT_INPUT)
                print("ğŸ¤– ì‹œìŠ¤í…œ: ìƒˆë¡œìš´ ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        elif choice == '2':
            self.state_machine.transition_to(ChatState.WAITING_USER_SELECT_FEATURE)
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
    
    def _extract_primary_keyword_from_question(self, question: Dict[str, Any]) -> str:
        """ë¬¸ì œì—ì„œ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        question_text = question.get('question', '').lower()
        explanation_text = question.get('explanation', '').lower()
        
        # ë¬¸ì œì™€ ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
        search_text = question_text + " " + explanation_text
        
        # êµ¬ì²´ì ì¸ Java í‚¤ì›Œë“œë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
        java_keywords = [
            'do-while', 'while', 'for', 'if', 'switch',  # ì œì–´ë¬¸
            'ë°°ì—´', 'array', '2ì°¨ì›', 'ë‹¤ì°¨ì›',  # ë°°ì—´
            'ë³€ìˆ˜', 'ìƒìˆ˜', 'íƒ€ì…', 'í˜•ë³€í™˜',  # ë³€ìˆ˜
            'í´ë˜ìŠ¤', 'ê°ì²´', 'ì¸ìŠ¤í„´ìŠ¤', 'ìƒì„±ì',  # ê°ì²´ì§€í–¥
            'ë©”ì„œë“œ', 'í•¨ìˆ˜', 'ì˜¤ë²„ë¡œë”©', 'ì˜¤ë²„ë¼ì´ë”©',  # ë©”ì„œë“œ
            'ìƒì†', 'ë‹¤í˜•ì„±', 'ìº¡ìŠí™”', 'ì¶”ìƒí™”',  # ê°ì²´ì§€í–¥ ê°œë…
            'ì˜ˆì™¸', 'try', 'catch', 'finally',  # ì˜ˆì™¸ì²˜ë¦¬
            'íŒ¨í‚¤ì§€', 'import', 'ì ‘ê·¼ì œì–´ì'  # ê¸°íƒ€
        ]
        
        # ê°€ì¥ êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¶€í„° ê²€ìƒ‰
        for keyword in java_keywords:
            if keyword in search_text:
                return keyword
        
        # ë¬¸ì œ í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • íŒ¨í„´ ê²€ìƒ‰
        if 'do-while' in search_text or 'do while' in search_text:
            return 'do-while'
        elif 'while' in search_text:
            return 'while'
        elif 'for' in search_text:
            return 'for'
        elif 'if' in search_text:
            return 'if'
        elif 'ë°°ì—´' in search_text or 'array' in search_text:
            return 'ë°°ì—´'
        elif 'ë³€ìˆ˜' in search_text:
            return 'ë³€ìˆ˜'
        
        # ì±•í„° ì •ë³´ì—ì„œ ì¶”ì¶œ
        chapter = question.get('chapter', '')
        if chapter:
            if 'ì¡°ê±´ë¬¸' in chapter or 'ë°˜ë³µë¬¸' in chapter:
                return 'ì œì–´ë¬¸'
            elif 'ë°°ì—´' in chapter:
                return 'ë°°ì—´'
            elif 'ë³€ìˆ˜' in chapter:
                return 'ë³€ìˆ˜'
            elif 'ê°ì²´' in chapter:
                return 'ê°ì²´ì§€í–¥'
        
        return "Java"
    
    def _search_pages_by_keyword(self, keyword: str) -> List[str]:
        """í‚¤ì›Œë“œë¡œ í˜ì´ì§€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            if not self.keywords_data:
                print("âš ï¸ í‚¤ì›Œë“œ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return []
            
            # ë™ì  ê²€ìƒ‰ ë¡œì§
            search_results = self._dynamic_keyword_search(keyword)
            
            if search_results:
                results = []
                for kw in search_results:
                    pages = kw['pages']
                    chapter = self._get_chapter_by_page(pages[0])
                    page_str = ", ".join(map(str, pages))
                    results.append(f"ğŸ“– {kw['word']} - í˜ì´ì§€ {page_str} (ì±•í„°: {chapter})")
                
                # ê²°ê³¼ë¥¼ í˜ì´ì§€ ìˆœìœ¼ë¡œ ì •ë ¬
                results.sort(key=lambda x: int(x.split('í˜ì´ì§€ ')[1].split()[0].split(',')[0]))
                return results
            else:
                # ìœ ì‚¬í•œ í‚¤ì›Œë“œ ì œì•ˆ
                suggestions = self._suggest_similar_keywords(keyword)
                if suggestions:
                    print(f"ğŸ’¡ ìœ ì‚¬í•œ í‚¤ì›Œë“œ: {', '.join(suggestions[:5])}")
                return []
                
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _dynamic_keyword_search(self, keyword: str) -> List[Dict[str, Any]]:
        """ë™ì  í‚¤ì›Œë“œ ê²€ìƒ‰ ë¡œì§"""
        keyword_lower = keyword.lower().strip()
        found_keywords = []
        
        # ê²€ìƒ‰ ì „ëµ ì •ì˜ (ìš°ì„ ìˆœìœ„ ìˆœ)
        search_strategies = [
            self._exact_match_search,
            self._word_boundary_search,
            self._partial_match_search,
            self._fuzzy_match_search
        ]
        
        # ê° ì „ëµì„ ìˆœì„œëŒ€ë¡œ ì‹œë„
        for strategy in search_strategies:
            results = strategy(keyword_lower)
            if results:
                found_keywords = results
                break
        
        return found_keywords
    
    def _exact_match_search(self, keyword: str) -> List[Dict[str, Any]]:
        """ì •í™•í•œ ì¼ì¹˜ ê²€ìƒ‰"""
        exact_matches = []
        for keyword_data in self.keywords_data:
            if keyword_data['word'].lower().strip() == keyword:
                exact_matches.append(keyword_data)
        return exact_matches
    
    def _word_boundary_search(self, keyword: str) -> List[Dict[str, Any]]:
        """ë‹¨ì–´ ê²½ê³„ ê²€ìƒ‰ (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ ë‹¨ì–´)"""
        boundary_matches = []
        for keyword_data in self.keywords_data:
            word = keyword_data['word'].lower().strip()
            # ë‹¨ì–´ ê²½ê³„ì—ì„œ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            if (keyword == word or 
                word.startswith(keyword + ' ') or 
                word.endswith(' ' + keyword) or
                ' ' + keyword + ' ' in word):
                boundary_matches.append(keyword_data)
        return boundary_matches
    
    def _partial_match_search(self, keyword: str) -> List[Dict[str, Any]]:
        """ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰"""
        partial_matches = []
        for keyword_data in self.keywords_data:
            word = keyword_data['word'].lower().strip()
            if keyword in word or word in keyword:
                partial_matches.append(keyword_data)
        return partial_matches
    
    def _fuzzy_match_search(self, keyword: str) -> List[Dict[str, Any]]:
        """ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰"""
        fuzzy_matches = []
        for keyword_data in self.keywords_data:
            word = keyword_data['word'].lower().strip()
            # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚° (ê³µí†µ ë¬¸ì ìˆ˜)
            common_chars = sum(1 for c in keyword if c in word)
            similarity = common_chars / max(len(keyword), len(word))
            if similarity > 0.6:  # 60% ì´ìƒ ìœ ì‚¬
                fuzzy_matches.append(keyword_data)
        return fuzzy_matches
    
    def _suggest_similar_keywords(self, keyword: str) -> List[str]:
        """ìœ ì‚¬í•œ í‚¤ì›Œë“œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤."""
        try:
            suggestions = []
            keyword_lower = keyword.lower()
            
            for keyword_data in self.keywords_data:
                word = keyword_data['word'].lower()
                # ë¶€ë¶„ ì¼ì¹˜ë‚˜ ìœ ì‚¬í•œ íŒ¨í„´ ì°¾ê¸°
                if (keyword_lower in word or 
                    word in keyword_lower or 
                    any(char in word for char in keyword_lower if char.isalpha())):
                    suggestions.append(keyword_data['word'])
            
            return suggestions[:10]  # ìµœëŒ€ 10ê°œ ì œì•ˆ
        except Exception:
            return []
    
    def _process_user_input(self, user_input: str) -> Optional[str]:
        """ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ì ì ˆí•œ ì±•í„°ëª…ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        input_lower = user_input.lower().strip()
        
        # ìˆ«ì ì…ë ¥ ì²˜ë¦¬ (ì±•í„° ë²ˆí˜¸)
        if input_lower.isdigit():
            chapter_num = int(input_lower)
            chapter_mapping = {
                1: "Chapter1 - ë³€ìˆ˜",
                2: "Chapter2 - ì—°ì‚°ì", 
                3: "Chapter3 - ì¡°ê±´ë¬¸ê³¼ ë°˜ë³µë¬¸",
                4: "Chapter4 - ë°°ì—´",
                5: "Chapter5 - ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° I"
            }
            if chapter_num in chapter_mapping:
                return chapter_mapping[chapter_num]
            else:
                print(f"âŒ ì±•í„° {chapter_num}ì€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (1-5)")
                return None
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤í•‘
        keyword_mapping = {
            "ë³€ìˆ˜": "Chapter1 - ë³€ìˆ˜",
            "ë§¤ê°œë³€ìˆ˜": "Chapter5 - ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° I",
            "parameter": "Chapter5 - ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° I",
            "ì—°ì‚°ì": "Chapter2 - ì—°ì‚°ì",
            "ì¡°ê±´ë¬¸": "Chapter3 - ì¡°ê±´ë¬¸ê³¼ ë°˜ë³µë¬¸",
            "ë°˜ë³µë¬¸": "Chapter3 - ì¡°ê±´ë¬¸ê³¼ ë°˜ë³µë¬¸",
            "for": "Chapter3 - ì¡°ê±´ë¬¸ê³¼ ë°˜ë³µë¬¸",
            "if": "Chapter3 - ì¡°ê±´ë¬¸ê³¼ ë°˜ë³µë¬¸",
            "while": "Chapter3 - ì¡°ê±´ë¬¸ê³¼ ë°˜ë³µë¬¸",
            "ë°°ì—´": "Chapter4 - ë°°ì—´",
            "ê°ì²´": "Chapter5 - ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° I",
            "í´ë˜ìŠ¤": "Chapter5 - ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° I",
            "ìƒì†": "Chapter5 - ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° I"
        }
        
        for keyword, chapter in keyword_mapping.items():
            if keyword in input_lower:
                return chapter
        
        # ì •í™•í•œ ì±•í„°ëª…ì¸ ê²½ìš°
        for chapter_name in self.chapter_pages.keys():
            if chapter_name.lower() in input_lower or input_lower in chapter_name.lower():
                return chapter_name
        
        # ì…ë ¥ì´ ê·¸ëŒ€ë¡œ ìœ íš¨í•œ ê²½ìš° (ê°œë… ì„¤ëª…ìš©)
        return user_input
    
    def _get_chapter_by_page(self, page: int) -> str:
        """í˜ì´ì§€ ë²ˆí˜¸ë¡œ ì±•í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
        for chapter_name, (start, end) in self.chapter_pages.items():
            if start <= page <= end:
                return chapter_name
        return "ì•Œ ìˆ˜ ì—†ëŠ” ì±•í„°"

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    system = JavaLearningSystem()
    system.run()

if __name__ == "__main__":
    main() 